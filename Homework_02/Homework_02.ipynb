{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhwlAhj7ZJ3k"
      },
      "source": [
        "## CS3570 Introduction to Multimedia Technology\n",
        "### Homework 02 Due: 11:59pm, 4/11/2025\n",
        "\n",
        "#### In the first part:\n",
        "You are required to implement DCT compression with different quality factors with the given image file (cat.jpg), and calculate the SSIM score of between the original image and compressed images.\n",
        "\n",
        "Here's the step:\n",
        "1. Convert the image from RGB to YCbCr following with chrominance subsampling 4:2:0.\n",
        "2. Divide the Y, Cb, Cr channels into blocks of 8 x 8 pixels.\n",
        "3. Shift values by -128 and transform the each 8x8 blocks from spatial domain to the DCT domain.\n",
        "4. Apply quantization with the provided quantization tables and quality factor.\n",
        "5. Reconstruct the image by taking inverse discrete cosine transform (IDCT) and shift values by +128.\n",
        "6. Reassemble the Y, Cb, Cr channels from 8x8 blocks.\n",
        "7. Upsample Cb, Cr and convert YCbCr back to RGB.\n",
        "8. Compute the PSNR score with reconstructed images and the original image.\n",
        "\n",
        "#### In the second part:\n",
        "You need to design and apply different FIR filters into separate three audio signals from the given audio file (HW2_Mix.wav). Next, you are asked to reduce the sampling rate of filtered signals. Finally, since the output audio signals are too simple, you should apply one-fold echo and multiple-fold echo to produce more complex music.\n",
        "\n",
        "Here's the step:\n",
        "1. Transform the input signal into frequency domain and plot the spectrum (magnitude in spectrum should be normalized to [0, 1]).\n",
        "2. Implement 3 different FIR filters to separate the three audio signals with Blackman window function (You have to pick the appropriate filter size, cut-off frequency, and window size).\n",
        "3. Implement 1D convolution on the input signal with your filters (zero padding).\n",
        "4. Reduce the sampling rates of the three separated songs to 2000Hz.\n",
        "5. Apply one-fold echo and multiple-fold echo on the signal that pass through the **low-pass filter**. (Please use the audio files before reducing sampling rates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUwq24UskRuq"
      },
      "source": [
        "### Reminder:\n",
        "* **The imported libraries are sufficient for this homework, you are not permitted to import other Python packages.**\n",
        "* **Your code must display and output your results to enable us to verify its correctness.**\n",
        "* **Please follow the instructions in the Jupyter Notebook and complete the parts marked as `\"TODO.\"`**\n",
        "* **Please compress your Jupyter Notebook file, image results from Q1 and audio results from Q2 in a zip file named HW2_xxxxxxxxx_ooo.zip, where xxxxxxxxx is your student ID and ooo is your name.**\n",
        "* **Homework should be submitted before the announced due time. Scores of late homework will be reduced by 20% per day.**\n",
        "* **If you encounter any problems or have questions, please post them on eeclass.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ62ePSQZv0e"
      },
      "source": [
        "## Part 1: DCT compression (40%)\n",
        "\n",
        "### Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sek-3hMGjXe_"
      },
      "outputs": [],
      "source": [
        "# !pip install opencv-python numpy matplotlib scipy\n",
        "\n",
        "import numpy as np\n",
        "from cv2 import imread, imwrite\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn3P_40QaXEu"
      },
      "source": [
        "### Define the quantization tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-pKawlWZAOoF"
      },
      "outputs": [],
      "source": [
        "# Quantization table for Y\n",
        "QT_L = np.array([\n",
        "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "    [24, 36, 55, 64, 81, 104, 113, 92],\n",
        "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "    [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "])\n",
        "\n",
        "# Quantization table for Cb, Cr\n",
        "QT_Chroma = np.array([\n",
        "    [17, 18, 24, 47, 99, 99, 99, 99],\n",
        "    [18, 21, 26, 66, 99, 99, 99, 99],\n",
        "    [24, 26, 56, 99, 99, 99, 99, 99],\n",
        "    [47, 66, 99, 99, 99, 99, 99, 99],\n",
        "    [99, 99, 99, 99, 99, 99, 99, 99],\n",
        "    [99, 99, 99, 99, 99, 99, 99, 99],\n",
        "    [99, 99, 99, 99, 99, 99, 99, 99],\n",
        "    [99, 99, 99, 99, 99, 99, 99, 99]\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THEt1vypaopa"
      },
      "source": [
        "### 1. Implement RGB to YCbCr and chrominance subsampling (4:2:0) (5%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2DU6EAA1lvCG"
      },
      "outputs": [],
      "source": [
        "def RGB2YCbCr(img):\n",
        "    '''\n",
        "    Input:\n",
        "        img: input image (RGB)\n",
        "    Output:\n",
        "        Y: Y channel\n",
        "        Cb: Cb channel\n",
        "        Cr: Cr channel\n",
        "    '''\n",
        "    H, W, _ = img.shape\n",
        "    img_ycbcr = np.zeros(img.shape)\n",
        "    Y = np.zeros((H, W))\n",
        "    Cb = np.zeros((H//2, W//2))\n",
        "    Cr = np.zeros((H//2, W//2))\n",
        "\n",
        "    # matrices for calculating RGB to YCbCr\n",
        "    M = np.array([[0.257, 0.564, 0.098],\n",
        "                  [-0.148, -0.291, 0.439],\n",
        "                  [0.439, -0.368, -0.071]])\n",
        "    C = np.array([16, 128, 128])\n",
        "\n",
        "    # [TODO]: Convert RGB to YCbCr with chrominance subsampling (4:2:0)\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            rgb = img[i, j].astype(float)\n",
        "            ycbcr = np.dot(M, rgb) + C\n",
        "            Y[i, j] = ycbcr[0]\n",
        "            img_ycbcr[i, j] = ycbcr\n",
        "    for i in range(0, H, 2):\n",
        "        for j in range(0, W, 2):\n",
        "            max_i = min(i + 2, H)\n",
        "            max_j = min(j + 2, W)\n",
        "            \n",
        "            cb_sum = 0\n",
        "            cr_sum = 0\n",
        "            count = 0\n",
        "            for bi in range(i, max_i):\n",
        "                for bj in range(j, max_j):\n",
        "                    cb_sum += img_ycbcr[bi, bj, 1]\n",
        "                    cr_sum += img_ycbcr[bi, bj, 2]\n",
        "                    count += 1\n",
        "            Cb[i//2, j//2] = cb_sum / count\n",
        "            Cr[i//2, j//2] = cr_sum / count\n",
        "    return Y, Cb, Cr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45cehAOVZLqm"
      },
      "source": [
        "### 2. Implement YCbCr to RGB (5%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "trdhfoza4nds"
      },
      "outputs": [],
      "source": [
        "def YCbCr2RGB(Y, Cb, Cr):\n",
        "    '''\n",
        "    Input:\n",
        "        Y: Y channel\n",
        "        Cb: Cb channel\n",
        "        Cr: Cr channel\n",
        "    Output:\n",
        "        img: output image (RGB)\n",
        "    '''\n",
        "    H, W = Y.shape\n",
        "    # [TODO]: Upsample Cb and Cr\n",
        "    Cb_upsample = np.repeat(np.repeat(Cb, 2, axis=0), 2, axis=1)[:H, :W]\n",
        "    Cr_upsample = np.repeat(np.repeat(Cr, 2, axis=0), 2, axis=1)[:H, :W]\n",
        "    img_YCbCr = np.stack((Y, Cb_upsample, Cr_upsample), axis=-1)\n",
        "    img = np.zeros((H, W, 3))\n",
        "\n",
        "    # matrices for converting YCbCr to RGB\n",
        "    M = np.array([[1.164, 0, 1.596],\n",
        "                  [1.164, -0.392, -0.813],\n",
        "                  [1.164, 2.017, 0]])\n",
        "    C = np.array([16, 128, 128])\n",
        "\n",
        "    # [TODO]: Convert YCbCr back to RGB\n",
        "    for i in range(H):\n",
        "            for j in range(W):\n",
        "                ycbcr = img_YCbCr[i, j].astype(float)\n",
        "                rgb = np.dot(M, (ycbcr - C))\n",
        "                img[i, j] = np.clip(rgb, 0, 255)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS9ITbUUa311"
      },
      "source": [
        "### 3. Implement Discrete Cosine Transform (DCT) (5%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "02XASCTlEXFp"
      },
      "outputs": [],
      "source": [
        "def DCT(f):\n",
        "    '''\n",
        "    Input:\n",
        "        f: image block\n",
        "    Output:\n",
        "        F: DCT transformed image block\n",
        "    '''\n",
        "    # [TODO]: Implement discrete cosine transform\n",
        "    # Assuming f is an 8x8 block\n",
        "    N = 8\n",
        "    F = np.zeros((N, N))\n",
        "    \n",
        "    # DCT transformation\n",
        "    for u in range(N):\n",
        "        for v in range(N):\n",
        "            # Normalization factors\n",
        "            cu = 1.0 / np.sqrt(2) if u == 0 else 1.0\n",
        "            cv = 1.0 / np.sqrt(2) if v == 0 else 1.0\n",
        "            \n",
        "            # Calculate the DCT coefficient at (u,v)\n",
        "            sum_val = 0.0\n",
        "            for x in range(N):\n",
        "                for y in range(N):\n",
        "                    # Apply the DCT formula\n",
        "                    sum_val += f[x, y] * np.cos((2*x+1)*u*np.pi/(2*N)) * np.cos((2*y+1)*v*np.pi/(2*N))\n",
        "            \n",
        "            # Apply scaling factors\n",
        "            F[u, v] = (2.0 / N) * cu * cv * sum_val\n",
        "    return F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODBSbt0TZbQR"
      },
      "source": [
        "### 4. Implement Inverse Discrete Cosine Transform (IDCT) (5%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GYAJDB7i7iKE"
      },
      "outputs": [],
      "source": [
        "def IDCT(F):\n",
        "    '''\n",
        "    Input:\n",
        "        F: DCT transformed image block\n",
        "    Output:\n",
        "        f: image block\n",
        "    '''\n",
        "    # [TODO]: Implement inverse discrete cosine transform\n",
        "    # Assuming F is an 8x8 block\n",
        "    N = 8\n",
        "    f = np.zeros((N, N))\n",
        "    \n",
        "    # IDCT transformation\n",
        "    for x in range(N):\n",
        "        for y in range(N):\n",
        "            # Calculate the pixel value at (x,y)\n",
        "            sum_val = 0.0\n",
        "            for u in range(N):\n",
        "                for v in range(N):\n",
        "                    # Normalization factors\n",
        "                    cu = 1.0 / np.sqrt(2) if u == 0 else 1.0\n",
        "                    cv = 1.0 / np.sqrt(2) if v == 0 else 1.0\n",
        "                    \n",
        "                    # Apply the IDCT formula\n",
        "                    sum_val += cu * cv * F[u, v] * np.cos((2*x+1)*u*np.pi/(2*N)) * np.cos((2*y+1)*v*np.pi/(2*N))\n",
        "            \n",
        "            # Apply scaling factor\n",
        "            f[x, y] = (2.0 / N) * sum_val\n",
        "    return f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oLCa9ljbZAh"
      },
      "source": [
        "### 5. Implement quantization with quality factor (5%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "duOW8_pBC9H8"
      },
      "outputs": [],
      "source": [
        "def quantize(img, Qf, chroma=True):\n",
        "    '''\n",
        "    Input:\n",
        "        img: image block\n",
        "        Qf: quality factor\n",
        "    Output:\n",
        "        img: quantized image block\n",
        "    '''\n",
        "    # [TODO]: Implement quantization\n",
        "    # Calculate scaling factor based on quality factor\n",
        "    if Qf >= 50:\n",
        "        S = (100 - Qf) / 50\n",
        "    else:\n",
        "        S = 50 / Qf\n",
        "    \n",
        "    # Scale the appropriate quantization table\n",
        "    if chroma:      # if input block is Cb or Cr\n",
        "        T_s = np.floor(QT_Chroma * S + 0.5)\n",
        "    else:           # if input block is Y\n",
        "        T_s = np.floor(QT_L * S + 0.5)\n",
        "    \n",
        "    # Prevent division by zero\n",
        "    T_s = np.maximum(T_s, 1)\n",
        "    \n",
        "    # Apply quantization by dividing and rounding\n",
        "    img = np.round(img / T_s)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPM73avtZrzK"
      },
      "source": [
        "### 6. DCT compression process (10%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5ut7x7QzCRk"
      },
      "outputs": [],
      "source": [
        "def dct_compression(img, Qf):\n",
        "    '''\n",
        "    Input:\n",
        "        img: input image\n",
        "        Qf: quality factor\n",
        "    Output:\n",
        "        compressed: compressed image\n",
        "    '''\n",
        "    height, weight, _ = img.shape\n",
        "    block_size = 8\n",
        "\n",
        "    Y, Cb, Cr = RGB2YCbCr(img)\n",
        "    Y_compressed = np.zeros(Y.shape)\n",
        "    Cb_compressed = np.zeros(Cb.shape)\n",
        "    Cr_compressed = np.zeros(Cr.shape)\n",
        "\n",
        "    # [TODO]: Implement the DCT compression process\n",
        "\n",
        "    # Process Y channel (luminance)\n",
        "    for i in range(0, height, block_size):\n",
        "        for j in range(0, weight, block_size):\n",
        "            # Get block boundaries (handle edge cases)\n",
        "            i_end = min(i + block_size, height)\n",
        "            j_end = min(j + block_size, weight)\n",
        "            \n",
        "            # Extract block and pad if needed\n",
        "            block = np.zeros((block_size, block_size))\n",
        "            block[:i_end-i, :j_end-j] = Y[i:i_end, j:j_end]\n",
        "            \n",
        "            # Step 3: Shift values by -128 and apply DCT\n",
        "            dct_block = DCT(block - 128)\n",
        "            \n",
        "            # Step 4: Apply quantization\n",
        "            quantized = quantize(dct_block, Qf, chroma=False)\n",
        "            \n",
        "            # Step 5: Inverse DCT and shift by +128\n",
        "            reconstructed = IDCT(quantized) + 128\n",
        "            \n",
        "            # Store in output array\n",
        "            Y_compressed[i:i_end, j:j_end] = reconstructed[:i_end-i, :j_end-j]\n",
        "\n",
        "    # Process Cb, Cr channels (chrominance) - already subsampled\n",
        "    cb_height, cb_width = Cb.shape\n",
        "    for i in range(0, cb_height, block_size):\n",
        "        for j in range(0, cb_width, block_size):\n",
        "            # Get block boundaries (handle edge cases)\n",
        "            i_end = min(i + block_size, cb_height)\n",
        "            j_end = min(j + block_size, cb_width)\n",
        "            \n",
        "            # Process Cb channel\n",
        "            cb_block = np.zeros((block_size, block_size))\n",
        "            cb_block[:i_end-i, :j_end-j] = Cb[i:i_end, j:j_end]\n",
        "            \n",
        "            dct_cb = DCT(cb_block - 128)\n",
        "            quantized_cb = quantize(dct_cb, Qf, chroma=True)\n",
        "            reconstructed_cb = IDCT(quantized_cb) + 128\n",
        "            \n",
        "            Cb_compressed[i:i_end, j:j_end] = reconstructed_cb[:i_end-i, :j_end-j]\n",
        "            \n",
        "            # Process Cr channel\n",
        "            cr_block = np.zeros((block_size, block_size))\n",
        "            cr_block[:i_end-i, :j_end-j] = Cr[i:i_end, j:j_end]\n",
        "            \n",
        "            dct_cr = DCT(cr_block - 128)\n",
        "            quantized_cr = quantize(dct_cr, Qf, chroma=True)\n",
        "            reconstructed_cr = IDCT(quantized_cr) + 128\n",
        "            \n",
        "            Cr_compressed[i:i_end, j:j_end] = reconstructed_cr[:i_end-i, :j_end-j]\n",
        "    \n",
        "    # Step 7: Convert YCbCr back to RGB\n",
        "    img_compressed = YCbCr2RGB(Y_compressed, Cb_compressed, Cr_compressed)\n",
        "\n",
        "    return np.clip(img_compressed, 0, 255).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv2Rtgf6yygT"
      },
      "source": [
        "### 7. Implement Peak Signal-to-Noise Ratio (PSNR) (5%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dm1LooK7y16G"
      },
      "outputs": [],
      "source": [
        "def PSNR(original, compressed):\n",
        "    '''\n",
        "    Input:\n",
        "        original: original image\n",
        "        compressed: compressed image\n",
        "    Output:\n",
        "        psnr: PSNR value\n",
        "    '''\n",
        "    # [TODO]: Calculate PSNR from the original image and the compressed image\n",
        "    # Convert images to float for calculation accuracy\n",
        "    original = original.astype(np.float64)\n",
        "    compressed = compressed.astype(np.float64)\n",
        "    \n",
        "    # Calculate Mean Squared Error (MSE)\n",
        "    mse = np.mean((original - compressed) ** 2)\n",
        "    \n",
        "    # Handle the case where images are identical\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    \n",
        "    # Maximum possible pixel value for 8-bit image\n",
        "    max_pixel = 255.0\n",
        "    \n",
        "    # Calculate PSNR\n",
        "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
        "    return psnr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSKycOMdbMvA"
      },
      "source": [
        "### Experiment with different quality factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QkgYHNKDjx3O"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'width' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m imread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBarbara.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m Qf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m80\u001b[39m\n\u001b[0;32m----> 4\u001b[0m compressed_img \u001b[38;5;241m=\u001b[39m \u001b[43mdct_compression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPSNR (Qf=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mQf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPSNR(image,\u001b[38;5;250m \u001b[39mcompressed_img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m imwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBarbara_quality-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mQf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, compressed_img)\n",
            "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mdct_compression\u001b[0;34m(img, Qf)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# [TODO]: Implement the DCT compression process\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Process Y channel (luminance)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, height, block_size):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[43mwidth\u001b[49m, block_size):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;66;03m# Get block boundaries (handle edge cases)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m         i_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(i \u001b[38;5;241m+\u001b[39m block_size, height)\n\u001b[1;32m     24\u001b[0m         j_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(j \u001b[38;5;241m+\u001b[39m block_size, width)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'width' is not defined"
          ]
        }
      ],
      "source": [
        "image = imread('Barbara.jpg')\n",
        "\n",
        "Qf = 80\n",
        "compressed_img = dct_compression(image, Qf)\n",
        "print(f\"PSNR (Qf={Qf}): {PSNR(image, compressed_img)}\")\n",
        "imwrite(f'Barbara_quality-{Qf}.jpg', compressed_img)\n",
        "\n",
        "Qf = 30\n",
        "compressed_img = dct_compression(image, Qf)\n",
        "print(f\"PSNR (Qf={Qf}): {PSNR(image, compressed_img)}\")\n",
        "imwrite(f'Barbara_quality-{Qf}.jpg', compressed_img)\n",
        "\n",
        "Qf = 5\n",
        "compressed_img = dct_compression(image, Qf)\n",
        "print(f\"PSNR (Qf={Qf}): {PSNR(image, compressed_img)}\")\n",
        "imwrite(f'Barbara_quality-{Qf}.jpg', compressed_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYz6noJ7caWr"
      },
      "source": [
        "## Part 2: FIR Filter (40%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PudndO7cezM"
      },
      "outputs": [],
      "source": [
        "from scipy.io import wavfile\n",
        "from scipy.fft import fft, fftfreq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1Ftg4-5WL68"
      },
      "source": [
        "### 1. Plot the frequency spectrum (5%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3_Xo56WdK8S"
      },
      "outputs": [],
      "source": [
        "def plot_spectrum(data, title, fs, xbond, ybond):\n",
        "    '''\n",
        "    Input:\n",
        "        data: input signal\n",
        "        title: title of the plot\n",
        "        fs: sampling frequency\n",
        "        xbond: x-axis range\n",
        "        ybond: y-axis range\n",
        "    '''\n",
        "    # TODO: FFT & Plot the magnitude spectrum of the input signal\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlim(xbond[0], xbond[1])\n",
        "    plt.ylim(ybond[0], ybond[1])\n",
        "    plt.plot(result[:, 0], result[:, 1])\n",
        "    plt.xlabel('Frequency (Hz)')\n",
        "    plt.ylabel('Magnitude')\n",
        "    plt.title(title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KmXs9DfWRNR"
      },
      "source": [
        "### 2. Implement three different filters - Lowpass, Highpass, Bandpass (10%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmGzh8wQFRx6"
      },
      "outputs": [],
      "source": [
        "def filter_generator(sample_rate, cutoff, filter_type, window_type, N):\n",
        "    '''\n",
        "    Input:\n",
        "        sample_rate: sampling frequency\n",
        "        cutoff: cutoff frequency\n",
        "        filter_type: type of filter (Lowpass, Highpass, Bandpass)\n",
        "        window_type: type of window function (Blackmann)\n",
        "        N: filter length (number of points in a filter), also the window length\n",
        "    Output:\n",
        "        filter: low-pass, high-pass, or band-pass filter\n",
        "    '''\n",
        "    # Normalize cutoff frequency\n",
        "    if filter_type == 'Lowpass' or filter_type == 'Highpass':\n",
        "        cutoff = cutoff / sample_rate\n",
        "    elif filter_type == 'Bandpass':\n",
        "        cutoff = [cutoff[0] / sample_rate, cutoff[1] / sample_rate]\n",
        "    else:\n",
        "        raise ValueError('Invalid filter type')\n",
        "\n",
        "    mid = N // 2\n",
        "    n = np.arange(-mid, mid+1)\n",
        "    n[mid] = 1\n",
        "    filter = np.zeros(2 * mid + 1)\n",
        "\n",
        "    # implement the ideal filter\n",
        "    if filter_type == 'Lowpass':\n",
        "        # [TODO]: Implement the Low-pass filter\n",
        "        pass\n",
        "    elif filter_type == 'Highpass':\n",
        "        # [TODO]: Implement the High-pass filter\n",
        "        pass\n",
        "    elif filter_type == 'Bandpass':\n",
        "        # [TODO]: Implement the Band-pass filter\n",
        "        pass\n",
        "\n",
        "    n = np.arange(0, N)\n",
        "    # implement the window function\n",
        "    if window_type == \"Blackmann\":\n",
        "        # [TODO]: Implement Blackmann window function\n",
        "        pass\n",
        "\n",
        "    return filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnvhZp8y96J8"
      },
      "outputs": [],
      "source": [
        "def plot_filter(filter, title):\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(filter)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('samples')\n",
        "    plt.ylabel('amplitude')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt9EYIy5Wj2W"
      },
      "source": [
        "### 3. Implement convolution function (10%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHRSS5Pb9QKY"
      },
      "outputs": [],
      "source": [
        "def convolve(signal , filter , N):\n",
        "    '''\n",
        "    Input:\n",
        "        signal: input signal\n",
        "        filter: filter\n",
        "        N: filter length\n",
        "    Output:\n",
        "        out: output signal\n",
        "    '''\n",
        "    len_signal = len(signal)\n",
        "    out = np.zeros(len(signal))\n",
        "\n",
        "    # [TODO]: Implement the 1D convolution operation\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmtvbdxHWrqb"
      },
      "source": [
        "### 4. Reduce sample rate (5%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y64DApZBGMj9"
      },
      "outputs": [],
      "source": [
        "def down_sampling(signal, fs, new_fs):\n",
        "    '''\n",
        "    Input:\n",
        "        signal: input signal\n",
        "        fs: sampling frequency\n",
        "        new_fs: new sampling frequency\n",
        "    Output:\n",
        "        output_signal: down-sampled signal\n",
        "    '''\n",
        "    # [TODO]: Implement the down-sampling operation\n",
        "\n",
        "    return signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCCVULucWvtH"
      },
      "source": [
        "### 5. Implement one-fold / multiple-fold echo (10%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bfRn5Zj-IzE"
      },
      "outputs": [],
      "source": [
        "def echo(signal_low, delay, alpha, fs):\n",
        "    '''\n",
        "    Input:\n",
        "        signal_low: input signal (time-domain)\n",
        "        delay: delay time\n",
        "        alpha: attenuation factor\n",
        "        fs: sampling frequency\n",
        "    Output:\n",
        "        output_echo_one: output signal with one-fold echo\n",
        "        output_echo_multiple: output signal with multiple-fold echo\n",
        "    '''\n",
        "\n",
        "    D = int(delay * fs)\n",
        "    input_len = len(signal_low)\n",
        "    output_echo_one = np.zeros(input_len + D)\n",
        "\n",
        "    #[TODO]: One-fold echo\n",
        "\n",
        "\n",
        "    D = int(delay * fs)\n",
        "    input_len = len(signal_low)\n",
        "    output_echo_multiple = np.zeros(input_len + D)\n",
        "\n",
        "    #[TODO]: Multiple-fold echo\n",
        "\n",
        "\n",
        "    output_echo_one = output_echo_one.astype(np.float32)\n",
        "    output_echo_multiple = output_echo_multiple.astype(np.float32)\n",
        "\n",
        "    return  output_echo_one, output_echo_multiple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfvN3VRiLEmG"
      },
      "source": [
        "### Note: There should be 10 images displayed below the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q8dq6AE29Dz"
      },
      "outputs": [],
      "source": [
        "# Read the wav file\n",
        "fs, data = wavfile.read('HW2_Mix.wav')\n",
        "\n",
        "# Plot the magnitude spectrum of the input signal\n",
        "plot_spectrum(data, \"Original spectrum\", fs, [0, 1500], [0, 2])\n",
        "\n",
        "# [TODO]: determine the cutoff frequency and window size\n",
        "fc_low =\n",
        "fc_high =\n",
        "fc_band = np.array([XXX, xxx])\n",
        "filter_size =\n",
        "\n",
        "# Generate filter with Blackmann window - Lowpass, Highpass, Bandpass\n",
        "lowpass_blackmann_filter = filter_generator(fs, fc_low, 'Lowpass', 'Blackmann', filter_size)\n",
        "highpass_blackmann_filter = filter_generator(fs, fc_high, 'Highpass', 'Blackmann', filter_size)\n",
        "bandpass_blackmann_filter = filter_generator(fs, fc_band, 'Bandpass', 'Blackmann', filter_size)\n",
        "\n",
        "# Plot filter shape\n",
        "plot_filter(lowpass_blackmann_filter, \"Lowpass Filter - Blackmann Window\")\n",
        "plot_filter(highpass_blackmann_filter, \"Highpass Filter - Blackmann Window\")\n",
        "plot_filter(bandpass_blackmann_filter, \"Bandpass Filter - Blackmann Window\")\n",
        "\n",
        "# Plot the magnitude spectrum of different filters\n",
        "plot_spectrum(lowpass_blackmann_filter, \"Lowpass Filter Spectrum - Blackmann Window\", fs, [0, 1500], [0, 2])\n",
        "plot_spectrum(highpass_blackmann_filter, \"Highpass Filter Spectrum - Blackmann Window\", fs, [0, 1500], [0, 2])\n",
        "plot_spectrum(bandpass_blackmann_filter, \"Bandpass Filter Spectrum - Blackmann Window\", fs, [0, 1500], [0, 2])\n",
        "\n",
        "# Convolve the input signal with different filters\n",
        "signal_low = convolve(data, lowpass_blackmann_filter, filter_size)\n",
        "signal_high = convolve(data, highpass_blackmann_filter, filter_size)\n",
        "signal_band = convolve(data, bandpass_blackmann_filter, filter_size)\n",
        "plot_spectrum(signal_low, \"Lowpass signal - Blackmann Window\", fs, [0, 1500], [0, 2])\n",
        "plot_spectrum(signal_high, \"Highpass signal - Blackmann Window\", fs, [0, 1500], [0, 2])\n",
        "plot_spectrum(signal_band, \"Bandpass signal - Blackmann Window\", fs, [0, 1500], [0, 2])\n",
        "\n",
        "# save audio\n",
        "wavfile.write(f\"Low_pass_{fc_low}.wav\", fs, signal_low)\n",
        "wavfile.write(f\"High_pass_{fc_high}.wav\", fs, signal_high)\n",
        "wavfile.write(f\"Band_pass_{fc_band[0]}_{fc_band[1]}.wav\", fs, signal_band)\n",
        "\n",
        "# Reduce sample rate\n",
        "new_fs = 2000\n",
        "signal_low_ds = down_sampling(signal_low, fs, new_fs)\n",
        "signal_high_ds = down_sampling(signal_high, fs, new_fs)\n",
        "signal_band_ds = down_sampling(signal_band, fs, new_fs)\n",
        "\n",
        "# You can also try setting 'new_fs' as 'fs' to see what happens.\n",
        "wavfile.write(f\"Low_pass_{fc_low}_2khz.wav\", new_fs, signal_low_ds)\n",
        "wavfile.write(f\"High_pass_{fc_high}_2khz.wav\", new_fs, signal_high_ds)\n",
        "wavfile.write(f\"Band_pass_{fc_band[0]}_{fc_band[1]}_2khz.wav\", new_fs, signal_band_ds)\n",
        "\n",
        "# Generate echo\n",
        "echo_one , echo_multiple = echo(signal_low, 1, 0.5, fs)\n",
        "wavfile.write('Echo_one.wav', fs, echo_one)\n",
        "wavfile.write(\"Echo_multiple.wav\", fs, echo_multiple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1ImC55w09C1"
      },
      "source": [
        "## Report (20%)\n",
        "\n",
        "Your report should cover the following aspects:\n",
        "* DCT compression\n",
        "    * Describe how you implemented the discrete cosine transform. (4%)\n",
        "    * Why should we convert image from RGB to YCbCr before compressing? (3%)\n",
        "    * Explain how can the quality factor affects the compression result. (3%)\n",
        "* FIR Filter\n",
        "    * Describe how you implemented the filter and convolutions to separate tha mixed song. And how did you determine the filter size and cut-off frequency. (4%)\n",
        "    * Compare the spectrum and shape of the filters. (3%)\n",
        "    * Compare the difference between the signals before and after reducing the sampling rates. (3%)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
